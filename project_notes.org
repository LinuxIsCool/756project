* Distributed Multi Agent Learning for Portfolio Management
CMPT 756: Systems for Big Data Project Proposal

** Subject
   Our subject is on virtualized trading agents that can be easily deployed to
   cloud environments. Agents refer to deep reinforcement learning based
   cryptocurrency trading bots as outlined in [[https://wwarxiv.org/pdf/1706.10059.pdf][this paper]], and implemented in
   [[https://github.com/zhengyaojiang/pgportfolio][this repo]]. By deploying trading agents to virtualized cloud environments we
   are able to easily scale up the number of active bots. By having many bots
   deployed we are able to do interesting things like parallel grid search over
   hyper-parameters, inter-agent communication, and genetic programming based bot
   evolution.
** Team
Shawn Anderson
Sethuraman Annamalai
Namita Shah
** Work Plan
   We have scheduled weekly meetings every Tuesday 2-5 pm. 
   Meetings will serve the following purposes:
       + Share progress of past week, get all team mates on same page
       + Brainstorm next steps and project ideas
       + Collaborative work session for project tasks
   In addition to meetings we will all work as individuals throughout the week
   to stay up to date, and accomplish assigned tasks for the project.
** Project Proposal
*** Introduction:
        In [[https://www.arxiv.org/pdf/1706.10059.pdf][Deep Reinforcement for the Financial Portfolio Management Problem]],
      the authors build a trading bot that re-optimizes a cryptocurrency
      portfolio at every time step. Our goal is to encapsulate the software that
      the authors release along with the paper, thus being able to spin up
      instances of the code(agents) in a cloud environment. Once the initial
      phase of cloud deployment is accomplished, there are various interesting
      scientific routes that could be taken from there.

*** Task 0: Deploy Remote Agent
    Create a cloud environment template which will be ready to run the
PGPortfolio software. Be able to instantiate an agent environment with an API
call. Have Agent request initialization parameters from server. Have agent
download its appropriate training and testing data. Perform and hardware queries
required (Attempt GPU?). Begin training and testing.
*** Task 1: Centralized Database 
    Maintain a database which exposes a web API as a RESTful interface. This
database will keep track of all agents that have been deployed, their
parameters, and performance metrics. A newly deployed agent will make a request
to the API for it's initialization parameters. From maintaining this data, we
are able to retrieve interesting statistics like which agents performed the best
over which periods, how many agents have been active at what times, which agent
made the most Bitcoin, ect.
*** Task 2: Plotting Performance 
    Once we have remote agents posting performance metrics to the data base, we would like to have some sort of visualization of these metrics.
 Visualization will serve as a sanity check to ensure that things are working properly, as well as it will serve as a powerful analysis and debugging tool as
we move on to more advanced tasks.
*** Task 3: Hyper-parameter optimization
        When agents spawn, they will request initialization parameters from the
server. Having a centralized initialization state dispatcher allows us to search
the hyper-parameter space intelligently. A naive example would be to perform an
exhaustive grid search over the hyper-parameters. But we can do better.
*** Task 4: Hyper-parameter evolution
    [[https://github.com/DEAP/deap][Distributed Evolutionary Algorithms in Python (DEAP)]] is a framework for
    state-space optimization using evolutionary approaches like populations,
    generations, fitness, mutation and prefix-trees. This could be used as the
    back-end for our parameter-initialization dispatcher.
*** Task 5: Additional learning features 
        In the paper, the agents are able to
      perform well with only historic price movement as input. Specifically, only
      three features: High, Low, Closing, for each time period (30 seconds). Additional features could be tested, for example, trade volume. 
*** Task 6: Transfer Learning
    Transfer learning is a method in deep learning in which internal representations learned in one setting are transferred to another setting. If
we could have each agent post it's learned parameters to a URL encoded as a prefix-tree, or genetic representation  that describes that agent. Then perhaps
we could have agents literally inherit the genes of their ancestors.
*** Task 7: Inter-agent communication
          Imagine two agents sharing information, for example, one agent could
        tell it's prediction's to another agent by concatenating it's output to
        another agent's input. Or consider inter-agent trading, which could circumvent market transaction fees.

*** What technologies are you using? What do you need?
     1. SFU-Cloud (VM Template, DB host)
     5. Python: Tensorflow, Django REST Framework, DEAP, SCOOP
     4. Database Backend
     6. Poloniex API for Data
     7. Optional: GPU

*** Questions / Concerns 
      1. Should agents stream data directly from source(poloniex) or from a central database?
         + We don't want to hammer the poloniex API, but it would be way easier if agents get their own data
      2. Why must this approach be distributed? Why is it not the same to simply run agents as separate processes on a single machine?
         + Perhaps we should spin up multiple agents as separate processes within cloud environments?     

*** Task Division
We will all work together to accomplish task 0. This will assure that all group members become familiar with the software and deployment technique. Other than that, we will mostly work together on tasks, but to introduce some paralellism, we will say Shawn is responsible for tasks 1,2; Sethu is responsible for 3,4; Namita is responsible for 5,6. Task 7 will remain as a bonus.

*** Timeline

**** Optimal
Task 0 is finished before March 2nd. Each member has acheived results on one of their two tasks by March 9th. Most members have acheived results on their second task by March 23rd. Remaining time is used to run experiments, investigate task 7 or additional tasks that arrise, and write the report.

**** Likely
Task 0 is finished before March 2nd. Each member has acheived results on one of their two tasks by March 16th. Each member has acheived results on their second task by April 1st. Remaining time is used to run experiments, investigate task 7, and write the report.

**** Backup
Task 0 is finished before March 9th. Some members have acheived results on one of their two tasks by March 16th. Members collaborate to assure the 5/8 tasks are acheived by April 1st. Remaining time is used to run experiments, investigate remaining tasks, and write the report.
     
** References
 1. [[https://arxiv.org/pdf/1706.10059.pdf][Deep Reinforcement Learning for Portfolio Optimization]]
 2. [[https://github.com/uber-common/deep-neuroevolution][Deep Neuro-Evolution]]
 
 3. [[https://www.oreilly.com/ideas/neuroevolution-a-different-kind-of-deep-learning][Neuroevolutin: A different kind of Deep Learning]]:
 
 "That is, neuroevolution is just as eligible to benefit from massive hardware investment as conventional deep learning, if not more. The advantage for neuroevolution, as with all evolutionary algorithms, is that a population of ANNs is intrinsically and easily processed in parallelâ€”if you have 100 ANNs in the population and 100 processors, you can evaluate all of those networks at the same time, in the time it takes to evaluate a single network. That kind of speed-up can radically expand the potential applications of the method."
 
 "ES is easy to implement and scale. Running on a computing cluster of 80 machines and 1,440 CPU cores, our implementation is able to train a 3D MuJoCo humanoid walker in only 10 minutes (A3C on 32 cores takes about 10 hours). Using 720 cores we can also obtain comparable performance to A3C on Atari while cutting down the training time from 1 day to 1 hour."

One consequence is that labs with access to large-scale computing clusters can see that they might be sitting on a neuroevolution goldmine, prompting a new generation of researchers and next-generation neuroevolution experiments to grow out of labs largely otherwise invested in conventional deep learning."

4. [[https://blog.openai.com/evolution-strategies/][OpenAI - Evolutionary Strategies]]:

"In particular, ES is simpler to implement (there is no need for backpropagation), it is easier to scale in a distributed setting, it does not suffer in settings with sparse rewards, and has fewer hyperparameters. This outcome is surprising because ES resembles simple hill-climbing in a high-dimensional space based only on finite differences along a few random directions at each step."

" Highly parallelizable. ES only requires workers to communicate a few scalars between each other, while in RL it is necessary to synchronize entire parameter vectors (which can be millions of numbers). Intuitively, this is because we control the random seeds on each worker, so each worker can locally reconstruct the perturbations of the other workers. Thus, all that we need to communicate between workers is the reward of each perturbation. As a result, we observed linear speedups in our experiments as we added on the order of thousands of CPU cores to the optimization."

"Since ES requires negligible communication between workers, we were able to solve one of the hardest MuJoCo tasks (a 3D humanoid) using 1,440 CPUs across 80 machines in only 10 minutes. As a comparison, in a typical setting 32 A3C workers on one machine would solve this task in about 10 hours. It is also possible that the performance of RL could also improve with more algorithmic and engineering effort, but we found that naively scaling A3C in a standard cloud CPU setting is challenging due to high communication bandwidth requirements."

 5. [[https://github.com/DEAP/deap][DEAP: Distributed Evolutionary Algorithms in Python]]
 6. [[https://github.com/soravux/scoop/][SCOOP: Scalable COncurrent Operations in Python]]
 7. [[https://en.wikipedia.org/wiki/Kubernetes][Kubernetes Cluster Management Software]]
 8. [[https://www.cs.cmu.edu/~muli/file/parameter_server_osdi14.pdf][Scaling Distributed Machine Learning with the Parameter Server]]
